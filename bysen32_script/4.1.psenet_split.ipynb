{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from utils.table2label import table2layout, fuse_gt_info, judge_error\n",
    "from utils.table_helper import correct_table\n",
    "from utils.format_translate import segmentation_to_bbox\n",
    "\n",
    "\n",
    "\n",
    "def table2label(table_dir, label_dir, error_file_path):\n",
    "    table_error = {}\n",
    "    json_files = sorted(glob(os.path.join(table_dir, '*.json')))\n",
    "    for idx, json_path in tqdm(enumerate(json_files), total=len(json_files)):\n",
    "        json_dir = os.path.dirname(json_path)\n",
    "        json_name = os.path.basename(json_path)\n",
    "        # json_name = \"06615.json\"\n",
    "        # json_path = os.path.join(json_dir, json_name)\n",
    "\n",
    "        json_id = json_name.split('.')[0]\n",
    "        table = json.load(open(json_path, 'r'))\n",
    "        \n",
    "        if not table['is_wireless']:\n",
    "            continue\n",
    "\n",
    "        # table['is_wireless'] = True\n",
    "\n",
    "        # table = correct_table(table)\n",
    "        try:\n",
    "            gt_label = table2layout(table)\n",
    "        except:\n",
    "            table_error[json_id] = 'table2layout error'\n",
    "            continue\n",
    "\n",
    "        ## 有线表格得到的bbox还是cell框，不是text框\n",
    "        try:\n",
    "            gt_label = fuse_gt_info(gt_label, table)\n",
    "        except:\n",
    "            table_error[json_id] = \"fuse_gt_info error\" # 仅有1cell的有线表格 滤过\n",
    "            continue\n",
    "\n",
    "        valid, msg = judge_error(table, gt_label)\n",
    "        if not valid:\n",
    "            print(json_name, msg)\n",
    "            table_error[json_id] = msg\n",
    "            continue\n",
    "\n",
    "        gt_json_path = os.path.join(label_dir, f'{json_id}-gt.json')\n",
    "        json.dump(gt_label, open(gt_json_path, 'w'), indent=4)\n",
    "    json.dump(table_error, open(error_file_path, 'w'), indent=4)\n",
    "\n",
    "    print('table error: {}'.format(len(table_error)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP.1 gen_gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4800/4800 [03:21<00:00, 23.81it/s] \n",
      "100%|██████████| 200/200 [00:07<00:00, 26.20it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "输入\n",
    "    训练集目录: {dataset_root}/train\n",
    "输出\n",
    "    训练集标注目录: {dataset_root}/train_gt_json/\n",
    "    {dataset_root}/train_error.json\n",
    "'''\n",
    "DATASET = \"train_jpg480max\"\n",
    "DATASET_ROOT = '/media/ubuntu/Date12/TableStruct/new_data'\n",
    "IFTABLE_LINE_ROOT = '/media/ubuntu/Date12/TableStruct/iftable_line'\n",
    "\n",
    "if os.path.exists(IFTABLE_LINE_ROOT):\n",
    "    shutil.rmtree(IFTABLE_LINE_ROOT)\n",
    "os.makedirs(os.path.join(IFTABLE_LINE_ROOT, \"imgs\", \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(IFTABLE_LINE_ROOT, \"imgs\", \"val\"), exist_ok=True)\n",
    "\n",
    "error_json = os.path.join(DATASET_ROOT, f\"{DATASET}_error.json\")\n",
    "error_json = json.load(open(error_json, 'r'))\n",
    "\n",
    "rc_label_dir = os.path.join(DATASET_ROOT, DATASET)\n",
    "\n",
    "\n",
    "json_paths = sorted(glob(os.path.join(rc_label_dir, '*.json')))\n",
    "json_paths = [json_path for json_path in json_paths if os.path.basename(json_path).split(\".\")[0] not in error_json]\n",
    "json_paths = np.array(json_paths)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kf.split(json_paths)):\n",
    "    train_set = json_paths[train_idx]\n",
    "    train_set = np.random.choice(train_set, 4800, replace=False)\n",
    "    val_set   = json_paths[val_idx]\n",
    "    val_set   = np.random.choice(val_set, 200, replace=False)\n",
    "\n",
    "    train_label = dict(images=[], annotations=[], categories=[dict(id=1, name=\"text\")])\n",
    "\n",
    "    line_anno_idx = 0\n",
    "    for idx, json_path in tqdm(enumerate(train_set), total=len(train_set)):\n",
    "        img_id = os.path.basename(json_path).split(\".\")[0]\n",
    "        img_path = os.path.join(DATASET_ROOT, f\"{DATASET}\", f\"{img_id}.jpg\")\n",
    "        height, width, _ = cv2.imread(img_path).shape\n",
    "        train_label[\"images\"].append(dict(file_name=f\"train/{img_id}.jpg\",\n",
    "                                          height=height, width=width,\n",
    "                                          segm_file=f'train/{img_id}.txt', id=idx))\n",
    "\n",
    "        rc_label = json.load(open(json_path, 'r'))\n",
    "        for line in rc_label['line']:\n",
    "            x0, y0, x1, y1 = segmentation_to_bbox([line])\n",
    "            x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n",
    "            seg = [[x0, y0, x0, y1, x1, y1, x1, y0]]\n",
    "            train_label[\"annotations\"].append(dict(id=line_anno_idx,\n",
    "                                                   image_id=idx,\n",
    "                                                   category_id=1,\n",
    "                                                   segmentation=seg,\n",
    "                                                   iscrowd=0,\n",
    "                                                   area=(x1-x0)*(y1-y0),\n",
    "                                                   bbox=[x0, y0, x1-x0, y1-y0]))\n",
    "            line_anno_idx += 1\n",
    "        dst_img_path = os.path.join(IFTABLE_LINE_ROOT, \"imgs\", \"train\", f\"{img_id}.jpg\") \n",
    "        shutil.copy2(img_path, dst_img_path)\n",
    "    train_json_path = os.path.join(IFTABLE_LINE_ROOT, \"instances_train.json\")\n",
    "    json.dump(train_label, open(train_json_path, 'w'), indent=4)\n",
    "\n",
    "\n",
    "    line_anno_idx = 0\n",
    "    val_label = dict(images=[], annotations=[], categories=[dict(id=1, name=\"text\")])\n",
    "    for idx, json_path in tqdm(enumerate(val_set), total=len(val_set)):\n",
    "        img_id = os.path.basename(json_path).split(\".\")[0]\n",
    "        img_path = os.path.join(DATASET_ROOT, f\"{DATASET}\", f\"{img_id}.jpg\")\n",
    "        height, width, _ = cv2.imread(img_path).shape\n",
    "        val_label[\"images\"].append(dict(file_name=f\"val/{img_id}.jpg\",\n",
    "                                        height=height, width=width,\n",
    "                                        segm_file=f'val/{img_id}.txt', id=idx))\n",
    "        \n",
    "        rc_label = json.load(open(json_path, 'r'))\n",
    "        for line in rc_label['line']:\n",
    "            x0, y0, x1, y1 = segmentation_to_bbox([line])\n",
    "            x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n",
    "            seg = [[x0, y0, x0, y1, x1, y1, x1, y0]]\n",
    "            val_label[\"annotations\"].append(dict(id=line_anno_idx,\n",
    "                                                 image_id=idx,\n",
    "                                                 category_id=1,\n",
    "                                                 segmentation=seg,\n",
    "                                                 iscrowd=0,\n",
    "                                                 area=(x1-x0)*(y1-y0),\n",
    "                                                 bbox=[x0, y0, x1-x0, y1-y0]))\n",
    "            line_anno_idx += 1\n",
    "        dst_img_path = os.path.join(IFTABLE_LINE_ROOT, \"imgs\", \"val\", f\"{img_id}.jpg\")\n",
    "        shutil.copy2(img_path, dst_img_path)\n",
    "    val_json_path = os.path.join(IFTABLE_LINE_ROOT, \"instances_val.json\")\n",
    "    json.dump(val_label, open(val_json_path, 'w'), indent=4)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9_torch1.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
